apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainingRuntime
metadata:
  name: wrapper-test-runtime
spec:
  mlPolicy:
    numNodes: 1
    torch:
      numProcPerNode: auto
  template:
    spec:
      replicatedJobs:
        - name: node
          template:
            metadata:
              labels:
                trainer.kubeflow.org/trainjob-ancestor-step: trainer
            spec:
              backoffLimit: 0
              template:
                spec:
                  containers:
                    - name: node
                      image: quay.io/modh/training:py311-cuda124-torch251
                      command:
                        - python
                        - "-c"
                        - |
                          # Replicate SDK's progression tracking using HuggingFace Transformers
                          # Tests actual callback behavior without SDK installation
                          import os
                          os.environ["TRANSFORMERS_NO_ADVISORY_WARNINGS"] = "1"

                          import json
                          import time
                          import threading
                          from http.server import HTTPServer, BaseHTTPRequestHandler
                          from transformers import TrainingArguments, Trainer, AutoModelForSequenceClassification, AutoTokenizer, TrainerCallback
                          from datasets import Dataset

                          # Ensure state.is_world_process_zero works correctly
                          os.environ.setdefault("RANK", "0")

                          print("[E2E] Using HuggingFace Transformers with SDK-replicated callbacks", flush=True)

                          # Global metrics state
                          _metrics = {
                              "progressPercentage": 0,
                              "estimatedRemainingSeconds": None,
                              "currentStep": 0,
                              "totalSteps": None,
                              "currentEpoch": 0.0,
                              "totalEpochs": None,
                              "trainMetrics": {},
                              "evalMetrics": {}
                          }
                          _lock = threading.Lock()

                          class MetricsHandler(BaseHTTPRequestHandler):
                              def do_GET(self):
                                  if self.path == '/metrics':
                                      with _lock:
                                          data = json.dumps(_metrics)
                                      self.send_response(200)
                                      self.send_header('Content-Type', 'application/json')
                                      self.end_headers()
                                      self.wfile.write(data.encode())
                                  else:
                                      self.send_error(404)
                              def log_message(self, *args): pass

                          # Replicate SDK's progression callback
                          class ProgressCallback(TrainerCallback):
                              def __init__(self):
                                  self.start_time = None
                                  self.server = None
                                  self.training_finished = False

                              def on_train_begin(self, args, state, control, **kwargs):
                                  self.start_time = time.time()

                                  with _lock:
                                      _metrics.update({
                                          "progressPercentage": 0,
                                          "estimatedRemainingSeconds": None,
                                          "currentStep": state.global_step or 0,
                                          "totalSteps": state.max_steps if state.max_steps > 0 else None,
                                          "currentEpoch": 0.0,
                                          "totalEpochs": int(args.num_train_epochs) if hasattr(args, 'num_train_epochs') else None
                                      })

                                  if state.is_world_process_zero:
                                      try:
                                          srv = HTTPServer(('0.0.0.0', 28080), MetricsHandler)
                                          threading.Thread(target=srv.serve_forever, daemon=True).start()
                                          self.server = srv
                                          print("[E2E] Metrics server started", flush=True)
                                      except Exception as e:
                                          print(f"[E2E] Warning: Failed to start metrics server: {e}", flush=True)

                              def on_step_end(self, args, state, control, **kwargs):
                                  # Don't overwrite completion state if training has already ended
                                  if not self.training_finished:
                                      step = state.global_step or 0
                                      total = state.max_steps
                                      pct = int(step / total * 100) if total > 0 else 0

                                      # Calculate estimated remaining time
                                      estimated_seconds = None
                                      if self.start_time and step > 0:
                                          elapsed = time.time() - self.start_time
                                          steps_per_sec = step / elapsed
                                          remaining_steps = total - step
                                          estimated_seconds = int(remaining_steps / steps_per_sec) if steps_per_sec > 0 else None

                                      with _lock:
                                          _metrics.update({
                                              "progressPercentage": pct,
                                              "currentStep": step,
                                              "totalSteps": total,
                                              "currentEpoch": float(state.epoch) if hasattr(state, 'epoch') and state.epoch else 0.0,
                                              "estimatedRemainingSeconds": estimated_seconds
                                          })

                              def on_log(self, args, state, control, logs=None, **kwargs):
                                  # Capture train metrics (loss, grad_norm, learning_rate, etc.)
                                  if logs:
                                      with _lock:
                                          # Filter to only include training metrics (not system metrics like epoch)
                                          train_metrics = {k: v for k, v in logs.items()
                                                          if k in ['loss', 'grad_norm', 'learning_rate', 'train_loss', 'train_runtime']}
                                          if train_metrics:
                                              _metrics["trainMetrics"].update(train_metrics)

                              def on_evaluate(self, args, state, control, metrics=None, **kwargs):
                                  # Capture eval metrics (accuracy, f1, etc.)
                                  if metrics:
                                      with _lock:
                                          eval_metrics = {k: v for k, v in metrics.items()
                                                         if k.startswith('eval_')}
                                          if eval_metrics:
                                              _metrics["evalMetrics"].update(eval_metrics)

                              def on_train_end(self, args, state, control, **kwargs):
                                  # Replicate SDK's on_train_end: update HTTP + write termination message
                                  self.training_finished = True

                                  # Update HTTP server metrics (matches SDK behavior)
                                  with _lock:
                                      _metrics.update({
                                          "progressPercentage": 100,
                                          "estimatedRemainingSeconds": 0,
                                          "currentStep": state.global_step,
                                          "totalSteps": state.max_steps,
                                          "currentEpoch": float(state.epoch) if hasattr(state, 'epoch') and state.epoch else 0.0,
                                          "totalEpochs": int(args.num_train_epochs) if hasattr(args, 'num_train_epochs') else None
                                      })

                                  if state.is_world_process_zero:
                                      try:
                                          with _lock:
                                              msg = {
                                                  "progressPercentage": 100,
                                                  "estimatedRemainingSeconds": 0,
                                                  "currentStep": state.global_step,
                                                  "totalSteps": state.max_steps,
                                                  "currentEpoch": float(state.epoch) if hasattr(state, 'epoch') and state.epoch else 0.0,
                                                  "totalEpochs": int(args.num_train_epochs) if hasattr(args, 'num_train_epochs') else None,
                                                  "trainMetrics": dict(_metrics.get("trainMetrics", {})),
                                                  "evalMetrics": dict(_metrics.get("evalMetrics", {}))
                                              }
                                          with open("/dev/termination-log", "w") as f:
                                              json.dump(msg, f)
                                          print("[E2E] Termination message written with train/eval metrics", flush=True)
                                      except Exception as e:
                                          print(f"[E2E] Warning: Failed to write termination message: {e}", flush=True)

                          # Quick training job
                          data = Dataset.from_dict({"text": ["test"] * 10, "label": [0] * 10})
                          tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
                          model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=2)
                          data = data.map(lambda x: tokenizer(x["text"], truncation=True, padding="max_length", max_length=32), batched=True)

                          args = TrainingArguments(
                              output_dir="/tmp/test", num_train_epochs=1, per_device_train_batch_size=2,
                              max_steps=10, save_strategy="no", logging_steps=2, report_to="none", disable_tqdm=True
                          )

                          trainer = Trainer(model=model, args=args, train_dataset=data, callbacks=[ProgressCallback()])
                          trainer.train()
                          print("[E2E] Training completed!")
                      readinessProbe:
                        httpGet:
                          path: /metrics
                          port: 28080
                        initialDelaySeconds: 2
                        periodSeconds: 1
                        timeoutSeconds: 1
                        failureThreshold: 2
                  restartPolicy: Never
